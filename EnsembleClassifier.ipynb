{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying MNIST with a Nengo Ensemble\n",
    "\n",
    "As a fun experiment, this notebook describes how to use a single, quite large neural ensemble in Nengo to perform an interesting classification task (namely, classifying images of handwritten digits from the MNIST database). Nengo ensembles, to explain, are collections of spiking neurons that respond selectively to different regions in an implicit representational space. This response selectivity is formally captured by assignment of a \"preferred direction\" of each neuron, which is a vector that identifies a representational state that triggers maximal spiking activity in the neuron. If the number of neurons is considerably larger than the dimensionality of the represenational space, and the preferred direction vectors (or 'encoders') are suitably distributed throughout the space, then it is possible to use linear regression to predict the values of arbitrary functions of the ensemble's representational state from the spiking activity of the ensemble's neurons. This works because the regression seeks out a set of linear weights in the very high-dimensional neuron space (where each neuron can be thought of as a feature that takes on different values depending on its input) that approximate a non-linear function in the lower-dimensional representational space. \n",
    "\n",
    "To demonstrate this use of linear weights to compute non-linear functions in context of image classification in nengo, we'll first load the images and perform some basic preprocessing to normalize the image vectors and convert the target classifications into binary vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cPickle\n",
    "\n",
    "with open('data/mnist.pkl', 'rb') as data:\n",
    "    train_set, cv_set, test_set = cPickle.load(data)\n",
    "\n",
    "def preprocess(data):\n",
    "    xs = data[0]\n",
    "    ys = data[1]\n",
    "    xs_norms = np.linalg.norm(xs, axis=1)\n",
    "    xs = np.divide(xs, xs_norms[:, np.newaxis]) \n",
    "    return xs, ys    \n",
    "\n",
    "def binarize(data):\n",
    "    indices = [tuple(data),tuple(range(len(data)))]\n",
    "    tmatrix = np.zeros((10, len(data)))\n",
    "    tmatrix[indices] = 1\n",
    "    return tmatrix \n",
    "\n",
    "train_data, train_targs = preprocess(train_set)\n",
    "test_data, test_targs = preprocess(test_set)\n",
    "\n",
    "train_targs = binarize(train_targs).T\n",
    "test_targs = binarize(test_targs).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now possible to define a nengo model that contains a single, very large ensemble whose decoders (i.e.the weights to used to compute a desired function from a set of neural activities) are optimized to minimize the squared error on the mapping between the training images in the MNIST dataset, and the binary vectors that indicate the correct classification decision for each of these images. In other words, the evaluation points used by nengo's decoder solver are the training images. For reasons concerning computational efficiency, only a portion of images are actually used in the example below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation finished in 0:00:06.                                                 \n"
     ]
    }
   ],
   "source": [
    "import nengo\n",
    "from nengo.utils.connection import target_function\n",
    "from nengo.solvers import LstsqL2, conjgrad\n",
    "\n",
    "model = nengo.Network()\n",
    "\n",
    "test_image = train_data[2345,:] # Pick an image to classify\n",
    "\n",
    "with model:\n",
    "    inp = nengo.Node(test_image)  \n",
    "    ens = nengo.Ensemble(n_neurons=50000, dimensions=784, radius=1)\n",
    "    out = nengo.Node(size_in=10)\n",
    "    \n",
    "    nengo.Connection(inp, ens)\n",
    "    nengo.Connection(ens, out, solver=LstsqL2(solver=conjgrad), \n",
    "                     **target_function(train_data[:15000,:], train_targs[:15000,:]))\n",
    "    \n",
    "    outProbe = nengo.Probe(out)\n",
    "    \n",
    "sim = nengo.Simulator(model)\n",
    "sim.run(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To test the classifier, we can compare the probed output of the ensemble during the simulation to the target value associated with the test image. If the dimension of the probed output with the maximum value is equal to the dimension of the target output that is non-zero, the ensemble can be treated as performing a correct classification. Here are the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble output: \n",
      "[ 0.17537283 -0.01310605 -0.02519724  0.09067443 -0.07917026 -0.05874371\n",
      "  0.83711041 -0.03059647 -0.02662353  0.12863922]\n",
      "\n",
      "Target output: \n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print 'Ensemble output: '\n",
    "print sim.data[outProbe][150]\n",
    "print ''\n",
    "print 'Target output: '\n",
    "print train_targs[2345,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this example at least, the classifier works quite well. More robust testing will be added shortly..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
